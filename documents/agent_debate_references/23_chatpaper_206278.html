<!DOCTYPE html><html  lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0, viewport-fit=cover"><title>From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection</title><script src="https://openpanel.dev/op1.js" defer async></script><link rel="stylesheet" href="https://cdn.pdppt.com/chatpaper/_nuxt/style.C8UmFHTW.css" crossorigin><link href="https://www.clarity.ms/tag/miya3qy90m" rel="preload" crossorigin="anonymous" referrerpolicy="no-referrer" fetchpriority="low" as="script"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/MmQ9F6jo.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/XZTJCa8x.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/DyAX2DkC.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/bUePjVg8.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/DjiwFUkp.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/CKpytZCs.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/Cxb5iPOI.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/DXKFEiGB.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/C687CptH.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/B-omsRtA.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/f2LxKUHZ.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/Dbrw4Urc.js"><link rel="modulepreload" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/BkrSrWmL.js"><link rel="preload" as="fetch" fetchpriority="low" crossorigin="anonymous" href="https://cdn.pdppt.com/chatpaper/_nuxt/builds/meta/9afa1f40-0943-4a2f-9a2d-dfcc61e83be5.json"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/error.tvJ2pCPV.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/loading.R5XN8ijB.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/banner-bg.B25YyVX9.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-1.C-wTMKJL.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-2.DcW65lKk.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-3.BcKdOcS4.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-4.Bq7Yme__.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/loading-dark.CPdTkWpg.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/banner-bg-dark.DaYh7taf.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-1-dark.DEGdtMvi.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-2-dark.CKf1DKWz.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-3-dark.DqukspRc.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/feature-4-dark.DyYmE5rl.png"><link rel="prefetch" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/CauVrkL1.js"><link rel="prefetch" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/i96o44gQ.js"><link rel="prefetch" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/BAIoDDil.js"><link rel="prefetch" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/BiKFYMmG.js"><link rel="prefetch" as="image" type="image/svg+xml" href="https://cdn.pdppt.com/chatpaper/_nuxt/product-hunt-dark-top.Dc_g4FJb.svg"><link rel="prefetch" as="video" href="https://cdn.pdppt.com/chatpaper/_nuxt/introduce.CCmReCZW.mp4"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/footer-bg.DpaYev1P.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/chatdoc.BPozj6zK.png"><link rel="prefetch" as="image" type="image/gif" href="https://cdn.pdppt.com/chatpaper/_nuxt/chatdoc-loading.BSerDD4s.gif"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/logo.CYVlVwPE.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/chatpaper.B67XpuJ1.png"><link rel="prefetch" as="script" crossorigin href="https://cdn.pdppt.com/chatpaper/_nuxt/D0xX-XDb.js"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/empty.trqJssam.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/collection-empty-light.C77iICby.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/collection-empty-dark.BhGd3W3E.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/search-empty-light.BVbdWlZ9.png"><link rel="prefetch" as="image" type="image/png" href="https://cdn.pdppt.com/chatpaper/_nuxt/search-empty-dark.DMXrkyLj.png"><meta name="format-detection" content="telephone=no,email=no,address=no"><link rel="icon" type="image/x-icon" href="/favicon.png"><script type="text/javascript">window.op=window.op||function(...args){(window.op.q=window.op.q||[]).push(args);};window.op('init',{clientId:'8be32dae-1404-49c8-8c90-06ef00c8ed2d',trackScreenViews:true,trackOutgoingLinks:true,trackAttributes:true});</script><link hid="i18n-xd" rel="alternate" href="http://chatpaper.com/paper/206278" hreflang="x-default"><link hid="i18n-alt-en" rel="alternate" href="http://chatpaper.com/paper/206278" hreflang="en"><link hid="i18n-alt-zh" rel="alternate" href="http://chatpaper.com/zh-CN/paper/206278" hreflang="zh"><link hid="i18n-alt-zh-CN" rel="alternate" href="http://chatpaper.com/zh-CN/paper/206278" hreflang="zh-CN"><link hid="i18n-alt-fr" rel="alternate" href="http://chatpaper.com/fr/paper/206278" hreflang="fr"><link hid="i18n-alt-de" rel="alternate" href="http://chatpaper.com/de/paper/206278" hreflang="de"><link hid="i18n-alt-es" rel="alternate" href="http://chatpaper.com/es/paper/206278" hreflang="es"><link hid="i18n-alt-ja" rel="alternate" href="http://chatpaper.com/ja/paper/206278" hreflang="ja"><link hid="i18n-alt-pt" rel="alternate" href="http://chatpaper.com/pt/paper/206278" hreflang="pt"><link hid="i18n-can" rel="canonical" href="http://chatpaper.com/paper/206278"><meta hid="i18n-og" property="og:locale" content="en"><meta hid="i18n-og-alt-zh-CN" property="og:locale:alternate" content="zh_CN"><meta hid="i18n-og-alt-fr" property="og:locale:alternate" content="fr"><meta hid="i18n-og-alt-de" property="og:locale:alternate" content="de"><meta hid="i18n-og-alt-es" property="og:locale:alternate" content="es"><meta hid="i18n-og-alt-ja" property="og:locale:alternate" content="ja"><meta hid="i18n-og-alt-pt" property="og:locale:alternate" content="pt"><meta name="keywords" content="Dailyarxiv,dailypaper,paper resarch,latest paper,Academic Research,arxiv research,summarization tool,ai paper tool,chat paper,chatpaper,chatdoc,chatpdf,pdfai,openai,ai summary,gpt-academic,chatgpt,Artificial intelligence,Computation and Language,Computer Vision and PatternRecognition,Machine Learning"><meta property="og:site_name" content="ChatPaper"><meta property="description" content="AIFo is an innovative agent-based framework that enhances the detection of AI-generated images by emulating human forensic reasoning through multi-agent collaboration, achieving 97.05% accuracy and outperforming traditional classifiers and state-of-the-art models."><meta property="og:title" content="From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection"><meta property="og:description" content="AIFo is an innovative agent-based framework that enhances the detection of AI-generated images by emulating human forensic reasoning through multi-agent collaboration, achieving 97.05% accuracy and outperforming traditional classifiers and state-of-the-art models."><meta name="twitter:title" content="From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection"><meta name="twitter:description" content="AIFo is an innovative agent-based framework that enhances the detection of AI-generated images by emulating human forensic reasoning through multi-agent collaboration, achieving 97.05% accuracy and outperforming traditional classifiers and state-of-the-art models."><meta property="og:url" content="http://chatpaper.com/paper/206278"><meta property="og:type" content="website"><meta property="og:image" content="https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/two_page_thumbnail.jpeg"><meta property="twitter:image" content="https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/two_page_thumbnail.jpeg"><meta property="twitter:card" content="summary_large_image"><script type="module" src="https://cdn.pdppt.com/chatpaper/_nuxt/MmQ9F6jo.js" crossorigin></script><script>"use strict";(()=>{const t=window,e=document.documentElement,c=["dark","light"],n=getStorageValue("localStorage","chatpaper-color-mode")||"system";let i=n==="system"?u():n;const r=e.getAttribute("data-color-mode-forced");r&&(i=r),l(i),t["__NUXT_COLOR_MODE__"]={preference:n,value:i,getColorScheme:u,addColorScheme:l,removeColorScheme:d};function l(o){const s=""+o+"",a="";e.classList?e.classList.add(s):e.className+=" "+s,a&&e.setAttribute("data-"+a,o)}function d(o){const s=""+o+"",a="";e.classList?e.classList.remove(s):e.className=e.className.replace(new RegExp(s,"g"),""),a&&e.removeAttribute("data-"+a)}function f(o){return t.matchMedia("(prefers-color-scheme"+o+")")}function u(){if(t.matchMedia&&f("").media!=="not all"){for(const o of c)if(f(":"+o).matches)return o}return"light"}})();function getStorageValue(t,e){switch(t){case"localStorage":return window.localStorage.getItem(e);case"sessionStorage":return window.sessionStorage.getItem(e);case"cookie":return getCookie(e);default:return null}}function getCookie(t){const c=("; "+window.document.cookie).split("; "+t+"=");if(c.length===2)return c.pop()?.split(";").shift()}</script></head><body><div id="__nuxt"><!--[--><div class="nuxt-loading-indicator" style="position:fixed;top:0;right:0;left:0;pointer-events:none;width:auto;height:3px;opacity:0;background:var(--el-color-primary);background-size:Infinity% auto;transform:scaleX(0%);transform-origin:left;transition:transform 0.1s, height 0.4s, opacity 0.4s;z-index:999999;"></div><!--[--><header class="chatpaper-header subpath-paper-id-header has-header default-layout-header has-border" data-v-71bb4d32 data-v-5422ff3b><div class="container header" data-v-5422ff3b><div class="left" data-v-5422ff3b><a href="/" class="logo" data-v-5422ff3b data-v-8ef2e9a7><img src="https://cdn.pdppt.com/chatpaper/_nuxt/logo.CYVlVwPE.png" alt="chatpaper" width="36" data-v-8ef2e9a7><h1 data-v-8ef2e9a7>ChatPaper</h1></a><a href="/" class="go-back" data-v-5422ff3b data-v-defcbb8a><svg aria-hidden="false" style="width:32px;height:32px;--color:var(--el-text-color-secondary);--408ac560:0 5px;" class="svg-icon-base" data-v-defcbb8a><use href="#icon-arrow-left"></use></svg></a></div><div style="" class="center" data-v-5422ff3b><span data-v-5422ff3b data-v-978be2cf></span></div><div class="right" data-v-5422ff3b><div style="" class="mobile-search-view-wrapper" data-v-5422ff3b><span data-v-5422ff3b data-v-1d8e258b></span></div><span data-v-5422ff3b data-v-dfdc6b90></span><div class="el-divider el-divider--vertical" style="--el-border-style:solid;" role="separator" data-v-5422ff3b><!--v-if--></div><a class="el-link el-link--primary" data-v-5422ff3b><!--v-if--><span class="el-link__inner"><!--[-->Sign in<!--]--></span><!--v-if--></a><!----></div></div><div class="container nav" data-v-5422ff3b><div class="nav" data-v-5422ff3b data-v-7f8d44a3><ul role="menubar" style="--el-menu-level:0;" class="el-menu el-menu--horizontal" data-v-7f8d44a3><!--[--><li class="el-menu-item menu-item" role="menuitem" tabindex="-1" data-v-7f8d44a3><!--[--><!--[--><a href="/interests" class="item-link" data-v-7f8d44a3>Interests</a><!--]--><!--[--><!--]--><!--]--></li><li class="el-menu-item is-active menu-item" role="menuitem" tabindex="-1" data-v-7f8d44a3><!--[--><!--[--><a href="/" class="item-link" data-v-7f8d44a3>arXiv</a><!--]--><!--[--><!--]--><!--]--></li><li class="el-menu-item menu-item" role="menuitem" tabindex="-1" data-v-7f8d44a3><!--[--><!--[--><a href="/venues" class="item-link" data-v-7f8d44a3>Venues</a><!--]--><!--[--><!--]--><!--]--></li><li class="el-menu-item menu-item special-menu-item" role="menuitem" tabindex="-1" data-v-7f8d44a3><!--[--><!--[--><span class="item-link" data-v-7f8d44a3>Collection</span><!--]--><!--[--><!--]--><!--]--></li><!--]--></ul><span data-v-7f8d44a3></span></div><nav class="mobile-nav" data-v-5422ff3b data-v-79b1a9b2><!--[--><a href="/interests" class="nav-item" data-v-79b1a9b2><span data-v-79b1a9b2>Interests</span><!----></a><a href="/" class="nav-item active" data-v-79b1a9b2><span data-v-79b1a9b2>arXiv</span><div class="icon-wrapper" data-v-79b1a9b2><svg aria-hidden="false" style="width:20px;height:20px;--color:var(--el-color-primary);--408ac560:0;" class="svg-icon-base" data-v-79b1a9b2><use href="#icon-arrow-down"></use></svg></div></a><a href="/venues" class="nav-item" data-v-79b1a9b2><span data-v-79b1a9b2>Venues</span><!----></a><!--]--></nav></div></header><div class="banner-container" style="display:none;" data-v-71bb4d32 data-v-735d00aa><div class="banner-wrapper" data-v-735d00aa><div class="banner" data-v-735d00aa><h2 class="title" data-v-735d00aa>AI-Powered Library for Researchers</h2><h3 class="desc" data-v-735d00aa><!--[--><span class="keyword" data-v-735d00aa>Track</span><!--]--> research interests, scroll daily paper feeds with <!--[--><span class="keyword" data-v-735d00aa>AI summary</span><!--]-->, 
 and <!--[--><span class="keyword" data-v-735d00aa>chat</span><!--]--> with bulk of files.</h3><span data-v-735d00aa></span><div data-v-735d00aa><span data-v-735d00aa data-v-978be2cf></span><span data-v-735d00aa data-v-1d8e258b></span></div></div></div></div><div class="subpath-paper-id simple layout-wrapper" data-v-71bb4d32><!----><div class="layout-container" data-v-71bb4d32><!--[--><!--[--><div class="paper-detail" data-v-a94f7ef7><div class="main container" data-v-a94f7ef7><div class="doc-list detailed" data-v-a94f7ef7 data-v-eb890f67><div class="list-container" data-v-eb890f67><!--[--><!--[--><div class="document detailed" data-doc="206278" data-visible="false" style="--06c512c2:transparent;--54bb8b88:0;" data-v-133aa1d6><div class="main-content" data-v-133aa1d6><div class="el-affix" style="height:;width:;" data-v-133aa1d6><div class="" style=""><!--[--><div class="doc-name" data-v-133aa1d6 data-v-e1cdcd82><div class="doc-name-main" data-v-e1cdcd82><!--[--><!--[--><!--[--><a href="/" class="go-back" data-v-a94f7ef7 data-v-defcbb8a><svg aria-hidden="false" style="width:32px;height:32px;--color:var(--el-text-color-secondary);--408ac560:0 5px;" class="svg-icon-base" data-v-defcbb8a><use href="#icon-go-back"></use></svg></a><!--]--><!--]--><!--]--><span class="serial-number" data-v-e1cdcd82>1.</span><a href="https://arxiv.org/abs/2511.00181" target="_blank" rel="noopener noreferrer" class="doc-name-content" data-v-e1cdcd82>From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection</a><!----></div><div class="doc-name-right" data-v-e1cdcd82><!----></div></div><!--]--></div></div><div class="doc-info" data-v-133aa1d6><!----><div class="doc-collect" data-v-133aa1d6 data-v-65e8560c><!--[--><a href="/?id=4&amp;auto_scroll=true" target="_blank" rel="noopener noreferrer" class="category-link" data-v-65e8560c data-v-65e8560c><span class="el-tag el-tag--primary el-tag--light common-tag" style="background-color:var(--el-bg-color-primary-light-2);" data-v-65e8560c data-v-d53d532b><span class="el-tag__content"><!--[--><!--[-->cs.CV<!--]--><!--]--></span><!--v-if--></span></a><!--]--><span class="el-tag el-tag--primary el-tag--light common-tag" style="background-color:var(--el-bg-color-primary-light-2);" data-v-65e8560c data-v-d53d532b><span class="el-tag__content"><!--[--><!--[--><span data-v-65e8560c>04 Nov 2025</span><!--]--><!--]--></span><!--v-if--></span><!----></div><div class="doc-author" data-v-133aa1d6 data-v-04f0fb05><svg aria-hidden="false" style="width:24px;height:24px;--color:var(--el-text-color-regular);--408ac560:0 10px 0 0;" class="svg-icon-base" data-v-04f0fb05><use href="#icon-author"></use></svg><!--[--><span class="text-wrapper" data-v-04f0fb05><span data-v-04f0fb05>Mengfei Liang, Yiting Qu, Yukun Jiang, Michael Backes, Yang Zhang</span></span><!--]--></div><div class="doc-organization" data-v-133aa1d6 data-v-3267b6db><svg aria-hidden="false" style="width:24px;height:24px;--color:var(--el-text-color-regular);--408ac560:0 10px 0 0;" class="svg-icon-base" data-v-3267b6db><use href="#icon-organization"></use></svg><span class="text-wrapper" data-v-3267b6db><span data-v-3267b6db><!--[--><span class="organization" data-v-3267b6db>CISPA Helmholtz Center for Information Security<!----></span><!--]--></span></span></div><!----><div id="abstract" class="doc-abstract" data-v-133aa1d6>The rapid evolution of AI-generated images poses unprecedented challenges to information integrity and media authenticity. Existing detection approaches suffer from fundamental limitations: traditional classifiers lack interpretability and fail to generalize across evolving generative models, while vision-language models (VLMs), despite their promise, remain constrained to single-shot analysis and pixel-level reasoning. To address these challenges, we introduce AIFo (Agent-based Image Forensics), a novel training-free framework that emulates human forensic investigation through multi-agent collaboration. Unlike conventional methods, our framework employs a set of forensic tools, including reverse image search, metadata extraction, pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based agents that collect, synthesize, and reason over cross-source evidence. When evidence is conflicting or insufficient, a structured multi-agent debate mechanism allows agents to exchange arguments and reach a reliable conclusion. Furthermore, we enhance the framework with a memory-augmented reasoning module that learns from historical cases to improve future detection accuracy. Our comprehensive evaluation spans 6,000 images across both controlled laboratory settings and challenging real-world scenarios, including images from modern generative platforms and diverse online sources. AIFo achieves 97.05% accuracy, substantially outperforming traditional classifiers and state-of-the-art VLMs. These results demonstrate that agent-based procedural reasoning offers a new paradigm for more robust, interpretable, and adaptable AI-generated image detection.</div><!----></div></div><!----><div style="--d23e7956:650px;" class="doc-summary" data-v-133aa1d6 data-v-37346210><p id="ai-summary" class="title" data-v-37346210><svg aria-hidden="false" style="width:24px;height:24px;--color:var(--el-text-color-yellow);--408ac560:0 5px;" class="svg-icon-base" data-v-37346210><use href="#icon-lamp-bulb"></use></svg><span class="text" data-v-37346210>AI Summary</span></p><div class="summary-container" data-v-37346210><div class="summary-content markdown-body part1" data-v-37346210>## Human-Like Procedural Reasoning

The AIFo (Agent-based Image Forensics) framework introduces a paradigm shift in AI-generated image detection by emulating the procedural reasoning of human forensic experts through a multi-agent system. Unlike traditional classifiers or single-shot vision-language models (VLMs), AIFo integrates multiple forensic tools—reverse image search, metadata extraction, pre-trained classifiers, and VLM-based analysis—into a coordinated workflow managed by specialized LLM-based agents. This design enables the system to collect, synthesize, and reason over cross-source evidence, mimicking the investigative process used by human analysts. The framework begins with an Evidence Gatherer Agent that systematically invokes tools from a forensic Toolbox to extract diverse forms of evidence. For instance, reverse image search identifies online provenance, metadata analysis inspects EXIF data for authenticity cues, pre-trained classifiers provide statistical confidence scores, and VLMs offer semantic-level visual reasoning. The collected evidence is then evaluated by a Reasoning Agent, which determines whether it is sufficient and consistent enough to support a final judgment. If the evidence is ambiguous or conflicting, a structured multi-agent debate mechanism is triggered, where two Debate Agents argue opposing positions under the supervision of a Judge Agent. This hierarchical structure ensures that decisions are not based solely on visual features but are derived from a comprehensive, interpretable, and dynamic reasoning process. A key innovation is the framework’s training-free nature: it does not require fine-tuning on labeled datasets, making it inherently generalizable across evolving generative models. Furthermore, AIFo incorporates a memory-augmented reasoning module that learns from historical cases, enabling continuous improvement over time—a capability absent in static detection systems. This human-like reasoning approach marks a significant departure from conventional binary classification, positioning AIFo as a robust, adaptable, and transparent solution for real-world forensic challenges.

![Figure 1: High-level overview of our proposed AIFo.](https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/figure_1.png

**Figure 1: High-level overview of our proposed AIFo.**



## Comprehensive Evaluation

AIFo is rigorously evaluated on a benchmark dataset of 6,000 images, equally divided between AI-generated and real images, and further categorized into controlled "in-the-lab" and real-world "in-the-wild" settings. The in-the-lab subset includes images from established datasets such as Flickr30K, ImageNet, and DIV2K for real images, and GenImage and FakeBench for AI-generated counterparts. The in-the-wild subset comprises images collected from online platforms like Flickr, Wikimedia Commons, Lexica, NightCafe, and Civitai, ensuring diversity in both content and generative models. This dataset spans over 20 different generative models, including Stable Diffusion, DALL·E, and community-finetuned variants, reflecting the complexity of real-world scenarios. AIFo is benchmarked against traditional classifiers (CNNSpot, DE-FAKE, PatchCraft) and state-of-the-art VLMs (GPT-4o, GPT-4.1), with performance measured using accuracy, precision, recall, and F1-score. The results show that AIFo achieves 97.05% accuracy, significantly outperforming GPT-4o (94.83%) and other baselines. Notably, AIFo maintains high performance in both lab and wild settings, demonstrating strong generalization. The framework also exhibits superior robustness under image perturbations such as blurring, sharpening, and Gaussian noise, where it consistently surpasses GPT-4o. For example, under blurring, AIFo achieves 90.47% accuracy compared to GPT-4o’s 88.18%, highlighting its resilience to visual degradation. These findings confirm that AIFo’s multi-source evidence integration and structured reasoning provide a more reliable and stable detection mechanism than single-model approaches. The evaluation also includes ablation studies and qualitative case analyses, further validating the contributions of each forensic tool and the effectiveness of the debate mechanism in resolving conflicting evidence.

![Table 3: Performance comparison of different methods on our benchmark dataset comprising three evaluation subsets: Overall, In-the-Lab, and In-the-Wild. Metrics reported are Accuracy (Acc), Precision (Prec), Recall (Rec), and F1-score (F1). Best results are highlighted in bold and second best results are underlined.](https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/table_3.png

**Table 3: Performance comparison of different methods on our benchmark dataset comprising three evaluation subsets: Overall, In-the-Lab, and In-the-Wild. Metrics reported are Accuracy (Acc), Precision (Prec), Recall (Rec), and F1-score (F1). Best results are highlighted in bold and second best results are underlined.**


</div><div class="need-auth summary-content markdown-body part2" data-v-37346210></div><!----><!----></div><!----></div></div><div class="extra-wrapper default-layout-extra-wrapper" style="--06c512c2:transparent;--54bb8b88:0;" data-v-133aa1d6><!----></div><!--]--><!--]--></div></div></div></div><!--]--><!--]--></div></div><div class="feature-wrapper" style="display:none;" data-v-71bb4d32 data-v-d6f53005><div class="container" data-v-d6f53005><h1 class="title" data-v-d6f53005>Why ChatPaper</h1><ul class="feature-list" data-v-d6f53005><!--[--><li class="feature-item" data-v-d6f53005><div class="title-wrapper" data-v-d6f53005><div class="icon-wrapper" data-v-d6f53005><svg aria-hidden="false" style="width:40px;height:40px;--color:var(--el-text-color-secondary);--408ac560:0;" class="svg-icon-base" data-v-d6f53005><use href="#icon-feature-1"></use></svg></div><span class="text" data-v-d6f53005>Interest-Driven Paper Curation</span></div><p class="desc" data-v-d6f53005>Describe your interests as you like, be it keywords or sentence, you’ll get relevant papers every day via AI semantic matching.</p><div class="bg feature-1-bg" data-v-d6f53005></div></li><li class="feature-item" data-v-d6f53005><div class="title-wrapper" data-v-d6f53005><div class="icon-wrapper" data-v-d6f53005><svg aria-hidden="false" style="width:40px;height:40px;--color:var(--el-text-color-secondary);--408ac560:0;" class="svg-icon-base" data-v-d6f53005><use href="#icon-feature-2"></use></svg></div><span class="text" data-v-d6f53005>Top Conferences, One-Stop</span></div><p class="desc" data-v-d6f53005>IJCAI, ICML, CVPR, KDD...  Access papers from top AI conferences, all in one tool, for free.</p><div class="bg feature-2-bg" data-v-d6f53005></div></li><li class="feature-item" data-v-d6f53005><div class="title-wrapper" data-v-d6f53005><div class="icon-wrapper" data-v-d6f53005><svg aria-hidden="false" style="width:40px;height:40px;--color:var(--el-text-color-secondary);--408ac560:0;" class="svg-icon-base" data-v-d6f53005><use href="#icon-feature-3"></use></svg></div><span class="text" data-v-d6f53005>Paper Management Made Easy</span></div><p class="desc" data-v-d6f53005>Keep your research organized with our bookmarking feature. Build a well-structured knowledge hub at your fingertips.</p><div class="bg feature-3-bg" data-v-d6f53005></div></li><li class="feature-item" data-v-d6f53005><div class="title-wrapper" data-v-d6f53005><div class="icon-wrapper" data-v-d6f53005><svg aria-hidden="false" style="width:40px;height:40px;--color:var(--el-text-color-secondary);--408ac560:0;" class="svg-icon-base" data-v-d6f53005><use href="#icon-feature-4"></use></svg></div><span class="text" data-v-d6f53005>Chat With Any Paper</span></div><p class="desc" data-v-d6f53005>Got questions? Ask in ChatDOC with one single click. Use AI to pull data, clarify terms, and verify facts with our precise word-level tracing feature.</p><div class="bg feature-4-bg" data-v-d6f53005></div></li><!--]--></ul></div></div><div class="introduce-wrapper" style="display:none;" data-v-71bb4d32 data-v-8ee4326b><div class="container" data-v-8ee4326b><h1 class="title" data-v-8ee4326b>See how it works</h1><h2 class="desc" data-v-8ee4326b>Watch now 1 min</h2><div class="player-wrapper" data-v-8ee4326b data-v-a7286da7><div data-v-a7286da7></div></div><div class="button-wrapper" data-v-8ee4326b><button ariadisabled="false" type="button" class="el-button el-button--primary el-button--large started-btn" style="" data-v-8ee4326b><!--v-if--><span class=""><!--[-->Get Started<!--]--></span></button><!--v-if--></div></div><!--[--><footer class="footer" data-v-71bb4d32 data-v-1866aef7><div class="link-wrapper" data-v-1866aef7><!--[--><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="/disclaim.html" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Disclaim<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://chatdoc.com/privacy_policy.html" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Policy<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://chatdoc.com/term_of_service.html" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Terms<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://twitter.com/chatdoc_ai" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Twitter<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://discord.gg/HFS8U89wXH" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Discord<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://chatdoc.com/blog/" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Blog<!--]--></span><!--v-if--></a><span class="dot" data-v-1866aef7>·</span></span><span class="link-item" data-v-1866aef7><a class="el-link el-link--default is-underline" href="https://chatdoc.com/log/" target="_blank" rel="noopener noreferrer" data-v-1866aef7><!--v-if--><span class="el-link__inner"><!--[-->Changelog<!--]--></span><!--v-if--></a><!----></span><!--]--></div><img class="footer-bg" src="https://cdn.pdppt.com/chatpaper/_nuxt/footer-bg.DpaYev1P.png" alt="footer" data-v-1866aef7></footer><!--]--></div><span data-v-71bb4d32></span><!--]--><div style="display:none;" data-git-branch="stable" data-git-version="2ced9ae" data-git-commit-hash="2ced9aedbe14eb5b74fb4208be1b75ef6bfef508" data-update-date="2026-01-14 10:36:31"></div><!--]--></div><div id="teleports"></div><script type="application/json" data-nuxt-data="nuxt-app" data-ssr="true" id="__NUXT_DATA__">[["ShallowReactive",1],{"data":2,"state":66,"once":73,"_errors":74,"serverRendered":71,"path":76,"pinia":77},["ShallowReactive",3],{"$doyyMropf4":4},[5],{"id":6,"source_type":7,"source_id":8,"title":9,"abstract":10,"update_date":11,"status":12,"summary_status":13,"organization":14,"first_image_url":15,"first_image_caption":16,"authors":17,"two_page_thumbnail":23,"category_list":24,"article_url":28,"pdf_url":29,"interactions":30,"summary":49,"summaryAnchorData":50},206278,"arxiv","2511.00181","From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection","The rapid evolution of AI-generated images poses unprecedented challenges to information integrity and media authenticity. Existing detection approaches suffer from fundamental limitations: traditional classifiers lack interpretability and fail to generalize across evolving generative models, while vision-language models (VLMs), despite their promise, remain constrained to single-shot analysis and pixel-level reasoning. To address these challenges, we introduce AIFo (Agent-based Image Forensics), a novel training-free framework that emulates human forensic investigation through multi-agent collaboration. Unlike conventional methods, our framework employs a set of forensic tools, including reverse image search, metadata extraction, pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based agents that collect, synthesize, and reason over cross-source evidence. When evidence is conflicting or insufficient, a structured multi-agent debate mechanism allows agents to exchange arguments and reach a reliable conclusion. Furthermore, we enhance the framework with a memory-augmented reasoning module that learns from historical cases to improve future detection accuracy. Our comprehensive evaluation spans 6,000 images across both controlled laboratory settings and challenging real-world scenarios, including images from modern generative platforms and diverse online sources. AIFo achieves 97.05% accuracy, substantially outperforming traditional classifiers and state-of-the-art VLMs. These results demonstrate that agent-based procedural reasoning offers a new paradigm for more robust, interpretable, and adaptable AI-generated image detection.",1762185600,"interaction_generated","parsed","CISPA Helmholtz Center for Information Security","https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/first_image.jpeg","High-level overview of our proposed AIFo.",[18,19,20,21,22],"Mengfei Liang","Yiting Qu","Yukun Jiang","Michael Backes","Yang Zhang","https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/two_page_thumbnail.jpeg",[25],{"id":26,"tag":27,"source_type":7},4,"cs.CV","https://arxiv.org/abs/2511.00181","https://arxiv.org/pdf/2511.00181",[31,37,41,45],{"language":32,"question":33,"answer":34,"question_type":35,"generated_from":36},"english","Too Long; Don't Read","AIFo is an innovative agent-based framework that enhances the detection of AI-generated images by emulating human forensic reasoning through multi-agent collaboration, achieving 97.05% accuracy and outperforming traditional classifiers and state-of-the-art models.","tldr","gpt",{"language":32,"question":38,"answer":39,"question_type":40,"generated_from":36},"What problem does the paper attempt to solve?","The paper attempts to solve the following problems:\n\n1. **The task the paper targets:**\n   - Detection of AI-generated images.\n\n2. **The current difficulties and challenges:**\n   - Existing detection methodologies, such as traditional classifiers and vision-language models (VLMs), struggle with:\n     - **Interpretability:** Difficulty in understanding the reasoning behind detection decisions.\n     - **Adaptability:** Inability to adjust to new types of AI-generated content as generative models evolve.\n     - **Robustness:** Challenges in maintaining performance in real-world scenarios, particularly with diverse and complex image data.\n\n3. **The motivation for the research:**\n   - To enhance the detection of AI-generated images by:\n     - Mimicking human forensic investigation processes through a collaborative multi-agent system.\n     - Integrating various forensic tools (e.g., reverse image searches, metadata extraction) to gather and synthesize evidence.\n     - Engaging in structured debates to resolve conflicting or insufficient evidence.\n     - Implementing a memory-augmented reasoning module to learn from historical cases and improve detection accuracy over time.","what",{"language":32,"question":42,"answer":43,"question_type":44,"generated_from":36},"What method does the paper propose?","The paper proposes the AIFo (Agent-based Image Forensics) framework, which includes several key components and methods:\n\n1. **Multi-Agent System**: A collaborative system that mimics human forensic investigation through multiple agents working together.\n\n2. **Forensic Toolbox**: A collection of various forensic tools that the framework utilizes, including:\n   - Reverse image searches\n   - Metadata extraction\n\n3. **Evidence Gatherer**: This component aggregates evidence from the forensic toolbox.\n\n4. **Reasoning Agent**: Evaluates the quality of the collected evidence to determine if it is sufficient and consistent enough to support a reliable judgment.\n\n5. **Debate Module**: Engages two Debate Agents in a structured debate when evidence is insufficient or conflicting. This module includes:\n   - Pro-Agent: Argues in favor of the image being AI-generated.\n   - Con-Agent: Argues in favor of the image being real.\n   - Judge Agent: Oversees the debate and produces the final judgment based on the arguments presented.\n\n6. **Memory-Augmented Reasoning Module**: Learns from historical cases to improve detection accuracy over time.\n\nThese components work together to enhance the detection of AI-generated images by integrating various evidence sources and simulating human-like reasoning processes.","how",{"language":32,"question":46,"answer":47,"question_type":48,"generated_from":36},"On which data was the experiment conducted?","The paper conducted experiments on a benchmark dataset comprising a total of 6,000 images, evenly distributed across two distinct settings: in-the-lab and in-the-wild. Here are the specific datasets and experimental steps/results:\n\n### Dataset Construction\n- **In-the-lab Setting**\n  - **Real Images**\n    - Flickr30k: 500 images\n    - ImageNet: 500 images\n    - DIV2K: 500 images\n  - **AI Images**\n    - GenImage: 800 images\n    - FakeBench: 700 images\n\n- **In-the-wild Setting**\n  - **Real Images**\n    - Holopix50k: 500 images\n    - Flickr: 500 images\n    - Wikimedia Commons: 500 images\n  - **AI Images**\n    - Lexica: 500 images\n    - NightCafe: 500 images\n    - Civitai: 500 images\n\n### Experimental Setup\n- **Baseline Methods**\n  - Compared against traditional classifiers:\n    - CNNSpot\n    - DE-FAKE\n    - PatchCraft\n  - Compared against vision-language models (VLMs):\n    - GPT-4.1\n    - GPT-4o\n\n### Evaluation Metrics\n- The evaluation was framed as a binary classification task to distinguish between AI-generated and real images, using metrics such as:\n  - Accuracy\n  - Precision\n  - Recall\n  - F1-score\n\n### Results\n- **Performance Comparison**\n  - AIFo (with debate): 97.05% accuracy\n  - AIFo (without debate): 96.35% accuracy\n  - GPT-4o: 94.83% accuracy\n  - GPT-4.1: 94.16% accuracy\n  - DE-FAKE: 71.42% accuracy\n  - PatchCraft: 65.17% accuracy\n  - CNNSpot: 52.77% accuracy\n\n### Analysis of Results\n- The framework demonstrated superior performance across both controlled (in-the-lab) and real-world (in-the-wild) scenarios, achieving:\n  - In-the-lab F1-score: 0.9735\n  - In-the-wild F1-score: 0.9661\n\nThis comprehensive evaluation highlights the effectiveness of the AIFo framework in detecting AI-generated images compared to traditional methods and VLMs.","experiment","## Human-Like Procedural Reasoning\n\nThe AIFo (Agent-based Image Forensics) framework introduces a paradigm shift in AI-generated image detection by emulating the procedural reasoning of human forensic experts through a multi-agent system. Unlike traditional classifiers or single-shot vision-language models (VLMs), AIFo integrates multiple forensic tools—reverse image search, metadata extraction, pre-trained classifiers, and VLM-based analysis—into a coordinated workflow managed by specialized LLM-based agents. This design enables the system to collect, synthesize, and reason over cross-source evidence, mimicking the investigative process used by human analysts. The framework begins with an Evidence Gatherer Agent that systematically invokes tools from a forensic Toolbox to extract diverse forms of evidence. For instance, reverse image search identifies online provenance, metadata analysis inspects EXIF data for authenticity cues, pre-trained classifiers provide statistical confidence scores, and VLMs offer semantic-level visual reasoning. The collected evidence is then evaluated by a Reasoning Agent, which determines whether it is sufficient and consistent enough to support a final judgment. If the evidence is ambiguous or conflicting, a structured multi-agent debate mechanism is triggered, where two Debate Agents argue opposing positions under the supervision of a Judge Agent. This hierarchical structure ensures that decisions are not based solely on visual features but are derived from a comprehensive, interpretable, and dynamic reasoning process. A key innovation is the framework’s training-free nature: it does not require fine-tuning on labeled datasets, making it inherently generalizable across evolving generative models. Furthermore, AIFo incorporates a memory-augmented reasoning module that learns from historical cases, enabling continuous improvement over time—a capability absent in static detection systems. This human-like reasoning approach marks a significant departure from conventional binary classification, positioning AIFo as a robust, adaptable, and transparent solution for real-world forensic challenges.\n\n![Figure 1: High-level overview of our proposed AIFo.](https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/figure_1.png 1: High-level overview of our proposed AIFo.**\n\n\n\n## Comprehensive Evaluation\n\nAIFo is rigorously evaluated on a benchmark dataset of 6,000 images, equally divided between AI-generated and real images, and further categorized into controlled \"in-the-lab\" and real-world \"in-the-wild\" settings. The in-the-lab subset includes images from established datasets such as Flickr30K, ImageNet, and DIV2K for real images, and GenImage and FakeBench for AI-generated counterparts. The in-the-wild subset comprises images collected from online platforms like Flickr, Wikimedia Commons, Lexica, NightCafe, and Civitai, ensuring diversity in both content and generative models. This dataset spans over 20 different generative models, including Stable Diffusion, DALL·E, and community-finetuned variants, reflecting the complexity of real-world scenarios. AIFo is benchmarked against traditional classifiers (CNNSpot, DE-FAKE, PatchCraft) and state-of-the-art VLMs (GPT-4o, GPT-4.1), with performance measured using accuracy, precision, recall, and F1-score. The results show that AIFo achieves 97.05% accuracy, significantly outperforming GPT-4o (94.83%) and other baselines. Notably, AIFo maintains high performance in both lab and wild settings, demonstrating strong generalization. The framework also exhibits superior robustness under image perturbations such as blurring, sharpening, and Gaussian noise, where it consistently surpasses GPT-4o. For example, under blurring, AIFo achieves 90.47% accuracy compared to GPT-4o’s 88.18%, highlighting its resilience to visual degradation. These findings confirm that AIFo’s multi-source evidence integration and structured reasoning provide a more reliable and stable detection mechanism than single-model approaches. The evaluation also includes ablation studies and qualitative case analyses, further validating the contributions of each forensic tool and the effectiveness of the debate mechanism in resolving conflicting evidence.\n\n![Table 3: Performance comparison of different methods on our benchmark dataset comprising three evaluation subsets: Overall, In-the-Lab, and In-the-Wild. Metrics reported are Accuracy (Acc), Precision (Prec), Recall (Rec), and F1-score (F1). Best results are highlighted in bold and second best results are underlined.](https://chatdoc-arxiv.oss-us-west-1.aliyuncs.com/images/arxiv/2511.00181/table_3.png 3: Performance comparison of different methods on our benchmark dataset comprising three evaluation subsets: Overall, In-the-Lab, and In-the-Wild. Metrics reported are Accuracy (Acc), Precision (Prec), Recall (Rec), and F1-score (F1). Best results are highlighted in bold and second best results are underlined.**\n\n\n",[51,55,59,63],{"id":52,"title":53,"children":54},1,"Human-Like Procedural Reasoning",[],{"id":56,"title":57,"children":58},2,"Comprehensive Evaluation",[],{"id":60,"title":61,"children":62},3,"Training-Free Core and Cross-Model Generalizability",[],{"id":26,"title":64,"children":65},"Tool Integration and Decision Mechanism",[],["Reactive",67],{"$snuxt-i18n-meta":68,"$scolor-mode":69},{},{"preference":70,"value":70,"unknown":71,"forced":72},"system",true,false,["Set"],["ShallowReactive",75],{"$doyyMropf4":-1},"/paper/206278",{"user":78,"arxiv":82,"category":85,"google":350,"search":352},{"userInfoLoaded":71,"userInfo":79,"userInterestList":80,"systemInterestList":81},null,[],[],{"dayList":83,"currentDate":84},[],1769179018,{"arxivCategoryList":86,"venuesCategoryList":87,"categoryRelationList":88},[],[],[89,104,110,185,245,266,311],{"id":52,"parent_id":79,"level":90,"children":91},0,[92,94,96,98,101],{"id":56,"parent_id":52,"level":52,"children":93},[],{"id":60,"parent_id":52,"level":52,"children":95},[],{"id":26,"parent_id":52,"level":52,"children":97},[],{"id":99,"parent_id":52,"level":52,"children":100},5,[],{"id":102,"parent_id":52,"level":52,"children":103},91,[],{"id":105,"parent_id":79,"level":90,"children":106},6,[107],{"id":108,"parent_id":105,"level":52,"children":109},7,[],{"id":111,"parent_id":79,"level":90,"children":112},8,[113,125,137,149,161,173],{"id":114,"parent_id":111,"level":52,"children":115},9,[116,119,122],{"id":117,"parent_id":114,"level":56,"children":118},10,[],{"id":120,"parent_id":114,"level":56,"children":121},11,[],{"id":123,"parent_id":114,"level":56,"children":124},12,[],{"id":126,"parent_id":111,"level":52,"children":127},13,[128,131,134],{"id":129,"parent_id":126,"level":56,"children":130},14,[],{"id":132,"parent_id":126,"level":56,"children":133},15,[],{"id":135,"parent_id":126,"level":56,"children":136},16,[],{"id":138,"parent_id":111,"level":52,"children":139},19,[140,143,146],{"id":141,"parent_id":138,"level":56,"children":142},20,[],{"id":144,"parent_id":138,"level":56,"children":145},21,[],{"id":147,"parent_id":138,"level":56,"children":148},22,[],{"id":150,"parent_id":111,"level":52,"children":151},56,[152,155,158],{"id":153,"parent_id":150,"level":56,"children":154},57,[],{"id":156,"parent_id":150,"level":56,"children":157},58,[],{"id":159,"parent_id":150,"level":56,"children":160},59,[],{"id":162,"parent_id":111,"level":52,"children":163},64,[164,167,170],{"id":165,"parent_id":162,"level":56,"children":166},65,[],{"id":168,"parent_id":162,"level":56,"children":169},66,[],{"id":171,"parent_id":162,"level":56,"children":172},67,[],{"id":174,"parent_id":111,"level":52,"children":175},76,[176,179,182],{"id":177,"parent_id":174,"level":56,"children":178},77,[],{"id":180,"parent_id":174,"level":56,"children":181},78,[],{"id":183,"parent_id":174,"level":56,"children":184},79,[],{"id":186,"parent_id":79,"level":90,"children":187},17,[188,191,209,224],{"id":189,"parent_id":186,"level":52,"children":190},18,[],{"id":192,"parent_id":186,"level":52,"children":193},25,[194,197,200,203,206],{"id":195,"parent_id":192,"level":56,"children":196},26,[],{"id":198,"parent_id":192,"level":56,"children":199},27,[],{"id":201,"parent_id":192,"level":56,"children":202},28,[],{"id":204,"parent_id":192,"level":56,"children":205},29,[],{"id":207,"parent_id":192,"level":56,"children":208},30,[],{"id":210,"parent_id":186,"level":52,"children":211},51,[212,215,218,221],{"id":213,"parent_id":210,"level":56,"children":214},52,[],{"id":216,"parent_id":210,"level":56,"children":217},53,[],{"id":219,"parent_id":210,"level":56,"children":220},54,[],{"id":222,"parent_id":210,"level":56,"children":223},55,[],{"id":225,"parent_id":186,"level":52,"children":226},80,[227,230,233,236,239,242],{"id":228,"parent_id":225,"level":56,"children":229},81,[],{"id":231,"parent_id":225,"level":56,"children":232},82,[],{"id":234,"parent_id":225,"level":56,"children":235},83,[],{"id":237,"parent_id":225,"level":56,"children":238},84,[],{"id":240,"parent_id":225,"level":56,"children":241},85,[],{"id":243,"parent_id":225,"level":56,"children":244},86,[],{"id":246,"parent_id":79,"level":90,"children":247},23,[248,251,260,263],{"id":249,"parent_id":246,"level":52,"children":250},24,[],{"id":252,"parent_id":246,"level":52,"children":253},60,[254,257],{"id":255,"parent_id":252,"level":56,"children":256},61,[],{"id":258,"parent_id":252,"level":56,"children":259},62,[],{"id":261,"parent_id":246,"level":52,"children":262},63,[],{"id":264,"parent_id":246,"level":52,"children":265},71,[],{"id":267,"parent_id":79,"level":90,"children":268},31,[269,299],{"id":270,"parent_id":267,"level":52,"children":271},32,[272,275,278,281,284,287,290,293,296],{"id":273,"parent_id":270,"level":56,"children":274},33,[],{"id":276,"parent_id":270,"level":56,"children":277},34,[],{"id":279,"parent_id":270,"level":56,"children":280},35,[],{"id":282,"parent_id":270,"level":56,"children":283},37,[],{"id":285,"parent_id":270,"level":56,"children":286},38,[],{"id":288,"parent_id":270,"level":56,"children":289},39,[],{"id":291,"parent_id":270,"level":56,"children":292},44,[],{"id":294,"parent_id":270,"level":56,"children":295},45,[],{"id":297,"parent_id":270,"level":56,"children":298},46,[],{"id":300,"parent_id":267,"level":52,"children":301},72,[302,305,308],{"id":303,"parent_id":300,"level":56,"children":304},73,[],{"id":306,"parent_id":300,"level":56,"children":307},74,[],{"id":309,"parent_id":300,"level":56,"children":310},75,[],{"id":312,"parent_id":79,"level":90,"children":313},40,[314,323,326,329,338],{"id":315,"parent_id":312,"level":52,"children":316},41,[317,320],{"id":318,"parent_id":315,"level":56,"children":319},42,[],{"id":321,"parent_id":315,"level":56,"children":322},43,[],{"id":324,"parent_id":312,"level":52,"children":325},47,[],{"id":327,"parent_id":312,"level":52,"children":328},48,[],{"id":330,"parent_id":312,"level":52,"children":331},68,[332,335],{"id":333,"parent_id":330,"level":56,"children":334},69,[],{"id":336,"parent_id":330,"level":56,"children":337},70,[],{"id":339,"parent_id":312,"level":52,"children":340},87,[341,344,347],{"id":342,"parent_id":339,"level":56,"children":343},88,[],{"id":345,"parent_id":339,"level":56,"children":346},89,[],{"id":348,"parent_id":339,"level":56,"children":349},90,[],{"clientId":351},"",{"keywords":351,"searchType":52,"searchOption":353},"all"]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{git:{branch:"stable",version:"2ced9ae",commitHash:"2ced9aedbe14eb5b74fb4208be1b75ef6bfef508",updateDate:"2026-01-14 10:36:31"},siteUrl:"https://chatpaper.com",jwtSecret:"b183a5824a12e10997b4210e64fff1f8","nuxt-scripts":{version:"",defaultScriptOptions:{trigger:"onNuxtReady"}},piniaPluginPersistedstate:{},i18n:{baseUrl:"",defaultLocale:"en-US",defaultDirection:"ltr",strategy:"prefix_and_default",lazy:true,rootRedirect:"",routesNameSeparator:"___",defaultLocaleRouteNameSuffix:"default",skipSettingLocaleOnNavigate:false,differentDomains:false,trailingSlash:false,locales:[{code:"en-US",language:"en",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"zh-CN",language:"zh-CN",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"fr",language:"fr",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"de",language:"de",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"es",language:"es",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"ja",language:"ja",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]},{code:"pt",language:"pt",files:[{path:"/opt/build/i18n/locales/en-US.js",cache:""}]}],detectBrowserLanguage:{alwaysRedirect:false,cookieCrossOrigin:false,cookieDomain:"",cookieKey:"i18n_redirected",cookieSecure:false,fallbackLocale:"",redirectOn:"root",useCookie:true},experimental:{localeDetector:"",switchLocalePathLinkSSR:false,autoImportTranslationFunctions:false,typedPages:true,typedOptionsAndMessages:false,generatedLocaleFilePathFormat:"absolute",alternateLinkCanonicalQueries:false,hmr:true},multiDomainLocales:false}},app:{baseURL:"/",buildId:"9afa1f40-0943-4a2f-9a2d-dfcc61e83be5",buildAssetsDir:"/_nuxt/",cdnURL:"https://cdn.pdppt.com/chatpaper"}}</script></body></html>