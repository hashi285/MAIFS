# **멀티 에이전트 이미지 포렌식 시스템 내 '에이전트 간 토론(Agent Debate)' 메커니즘의 구체적 설계 및 구현 방안과 연구 발전 방향 조사**

## **1\. 핵심 요약 (Executive Summary)**

생성형 인공지능(Generative AI) 기술의 비약적인 발전은 디지털 미디어의 신뢰성을 근본적으로 위협하고 있다. 특히, GAN(Generative Adversarial Networks) 및 확산 모델(Diffusion Models) 기반의 정교한 위·변조 기술은 기존의 단일 모달리티(Single-Modality) 기반 포렌식 탐지 모델의 한계를 드러내고 있다. 단일 탐지 모델은 특정 아티팩트(Artifact)에 과적합(Overfitting)되거나, 새로운 생성 기법에 취약한 '오픈 셋(Open-Set)' 문제를 해결하지 못하는 치명적인 약점을 가진다. 이에 대한 대응책으로, 다양한 분석 관점을 가진 여러 에이전트가 협력하여 결론을 도출하는 멀티 에이전트 시스템(Multi-Agent System, MAS)이 차세대 포렌식의 핵심 패러다임으로 부상하고 있다.

본 보고서는 멀티 에이전트 이미지 포렌식 시스템, 특히 '하이브리드 포렌식 모델(Hybrid Forensic Model)' 내에서 **'에이전트 간 토론(Agent Debate)'** 메커니즘을 구체적으로 설계하고 구현하는 방안을 심도 있게 다룬다. 본 연구는 단순한 확률적 앙상블(Ensemble)을 넘어, 에이전트들이 각자의 분석 결과(증거)를 바탕으로 논리적 공방을 펼치고, 상호 검증을 통해 불확실성을 해소하는 능동적 추론 과정을 설계하는 데 초점을 맞춘다.

이를 위해 본 보고서는 다음의 핵심 요소들을 통합적으로 분석하고 제안한다:

1. **아키텍처 설계:** 주파수(Frequency), 노이즈(Noise), 공간(Spatial), 워터마크(Watermark) 분석을 수행하는 4가지 전문 에이전트와 이들의 충돌을 조정하는 **COBRA(COnsensus-Based RewArd)** 퓨전 엔진 기반의 시스템 구조를 제안한다.1  
2. **토론 프로토콜(Debate Protocol):** MAD-Sherlock 및 AIFo(Agent-based Image Forensics) 프레임워크에서 영감을 받아, 증거 수집(Evidence Gathering), 반박(Rebuttal), 재검토(Refinement), 판결(Judgment)로 이어지는 단계별 토론 절차를 설계한다.2  
3. **합의 알고리즘:** 신뢰 기반 가중치(Root-of-Trust, RoT), 동적 신뢰도 가중(Dynamic Reliability Weighted Aggregation, DRWA), 적응형 분산 유도 주의(Adaptive Variance-Guided Attention, AVGA) 등 COBRA 프레임워크의 합의 전략을 포렌식 도메인에 맞게 재정의하고 수식화한다.1  
4. **구현 방안:** LangGraph 및 AutoGen과 같은 최신 에이전트 오케스트레이션 프레임워크를 활용한 구체적인 코드 레벨의 구현 패턴과 상태 관리(State Management) 전략을 제시한다.4

본 보고서는 에이전트 간 토론이 단순한 정확도 향상을 넘어, 포렌식 판정의 설명 가능성(Explainability)을 획기적으로 개선하고, 적대적 공격(Adversarial Attack)에 대한 강건성(Robustness)을 확보하는 데 필수적임을 논증한다. 마지막으로, 게임 이론(Game Theory) 기반의 최적화와 재귀적 토론(Recursive Debate) 등 향후 연구 발전 방향을 제시하여 이 분야의 기술적 로드맵을 완성한다.

## ---

**2\. 서론 (Introduction)**

### **2.1 연구 배경: 디지털 무결성의 위기와 포렌식의 한계**

디지털 이미지는 현대 사회에서 정보 전달의 핵심 매체이나, DALL-E 3, Midjourney v6, Stable Diffusion XL 등 고도화된 생성 모델의 등장은 '보는 것이 믿는 것'이라는 오랜 격언을 무력화시켰다. 초기 딥페이크(Deepfake) 기술은 부자연스러운 경계선이나 텍스처 아티팩트를 남겨 비교적 탐지가 용이했으나, 최신 확산 모델은 주파수 영역의 이상 징후를 억제하고 센서 노이즈까지 모방하는 수준에 이르렀다.

기존의 딥러닝 기반 포렌식 탐지기(Detector)들은 대부분 '블랙박스(Black-box)' 분류기로 작동하며, "이 이미지는 99% 확률로 가짜다"라는 결과만을 제시할 뿐, "왜 가짜인지"에 대한 논리적 근거를 설명하지 못한다. 또한, 특정 생성 모델(예: GAN)의 데이터셋으로 훈련된 탐지기는 구조가 다른 모델(예: Diffusion)이 생성한 이미지에 대해 맹목적인 확신을 갖거나 완전히 실패하는 일반화 오류를 범하기 쉽다.

### **2.2 멀티 에이전트 시스템(MAS)으로의 패러다임 전환**

이러한 단일 모델의 한계를 극복하기 위해, 학계와 산업계는 '전문가 혼합(Mixture of Experts)' 개념을 확장한 멀티 에이전트 시스템(MAS)으로 시선을 돌리고 있다. MAS 기반 포렌식의 핵심 전제는 \*\*"완벽한 위조는 없다"\*\*는 것이다. 시각적(Spatial)으로 완벽해 보이는 이미지라 할지라도, 주파수(Frequency) 도메인, 노이즈 잔차(Noise Residual), 또는 메타데이터(Metadata) 수준에서는 반드시 불일치(Inconsistency)가 존재한다는 가정이다.

그러나 단순히 여러 모델의 출력을 평균 내는(Averaging) 방식은 강력한 오답(Strong Wrong Prediction)에 취약하다. 예를 들어, 3개의 에이전트 중 2개가 정교한 적대적 공격에 속아 '진본'이라고 판정하고, 1개의 에이전트만이 미세한 주파수 결함을 근거로 '위조'라고 주장할 때, 단순 다수결은 오판을 초래한다. 따라서 에이전트들이 서로의 근거를 제시하고 비판하며 합의에 도달하는 **'토론(Debate)' 메커니즘**이 필수적으로 요구된다.

### **2.3 보고서의 목적 및 범위**

본 보고서는 하이브리드 포렌식 모델 구축 프로젝트 1의 아키텍처를 기반으로, **에이전트 간 토론 메커니즘**을 체계적으로 설계하고 구현하는 가이드를 제공하는 것을 목적으로 한다. 보고서의 범위는 다음과 같다:

* **이론적 배경:** COBRA 프레임워크 1와 MAD-Sherlock 2 등 최신 연구에 기반한 토론 및 합의 이론 분석.  
* **시스템 설계:** 4가지 전문 분석 브랜치(Branch)와 퓨전 엔진의 상세 설계.  
* **알고리즘:** RoT, DRWA, AVGA 및 뎀스터-쉐퍼 이론(Dempster-Shafer Theory)의 수식적 적용.  
* **구현:** LangGraph 등을 활용한 실제 워크플로우 및 코드 패턴.  
* **미래 전망:** 기술적 한계 극복을 위한 중장기 연구 주제.

## ---

**3\. 이론적 프레임워크: 합의와 토론의 매커니즘 (Theoretical Framework)**

### **3.1 AI 에이전트의 인지 부조화와 토론의 필요성**

단일 AI 모델은 본질적으로 자신의 출력에 대한 확신 편향(Overconfidence Bias)을 가진다. 특히 '환각(Hallucination)' 현상은 생성 모델뿐만 아니라 탐지 모델에서도 발생하여, 진본 이미지를 위조로 잘못 판정하는 위양성(False Positive) 문제를 야기한다.

\*\*에이전트 간 토론(Multi-Agent Debate, MAD)\*\*은 이러한 편향을 상쇄하기 위해 도입되었다. Du et al. 6과 Liang et al. 7의 연구에 따르면, 여러 LLM 에이전트가 "Tit-for-Tat" 방식의 논쟁을 벌일 때, 단일 에이전트가 간과한 논리적 오류를 상호 수정하고, '사고의 퇴보(Degeneration of Thought)'를 방지할 수 있음이 입증되었다. 포렌식 영역에서 이는 다음과 같은 형태로 적용된다:

* **상호 검증(Cross-Verification):** 시각적 분석 에이전트가 "자연스러운 조명"을 근거로 진본을 주장할 때, 물리적 노이즈 분석 에이전트가 "센서 패턴 부재"를 근거로 반박한다.  
* **증거 기반 추론:** 에이전트는 단순한 확률값이 아닌, 판단의 근거(예: FFT 스펙트럼의 그리드 패턴)를 제시해야 한다.

### **3.2 COBRA 프레임워크의 재해석: 악성 피드백에서 위조 증거로**

본 보고서의 핵심 이론적 토대는 **COBRA(COnsensus-Based RewArd)** 프레임워크이다.1 COBRA는 원래 RLHF(Reinforcement Learning from Human Feedback) 과정에서 악의적인 인간 평가자의 피드백을 걸러내기 위해 개발되었으나, 그 매커니즘은 포렌식 시스템의 '오류를 범하는 에이전트'를 식별하는 데 완벽하게 부합한다.

포렌식 시스템에서의 '악성(Malicious)' 에이전트는 공격자에게 매수된 것이 아니라, 적대적 공격(Adversarial Attack)이나 새로운 생성 기법에 의해 **기만당한(Compromised)** 에이전트를 의미한다. COBRA의 코호트(Cohort) 시스템은 에이전트들을 '신뢰(Trusted)' 그룹과 '비신뢰(Untrusted)' 그룹으로 동적으로 분류하여, 다수의 에이전트가 기만당한 상황(Mixed-Trust Scenario)에서도 올바른 판정을 내릴 수 있도록 돕는다.1

### **3.3 증거 이론(Evidence Theory)과 불확실성**

토론의 결과는 단순한 다수결(Majority Voting)이 되어서는 안 된다. 본 시스템은 \*\*뎀스터-쉐퍼 이론(Dempster-Shafer Theory, DST)\*\*과 \*\*증거적 딥러닝(Evidential Deep Learning, EDL)\*\*을 결합하여, 각 에이전트의 주장을 확률(Probability)이 아닌 믿음(Belief)과 불확실성(Uncertainty)으로 모델링한다.1

* **믿음 질량(Mass Function):** 에이전트가 특정 클래스(Real/Fake)를 지지하는 정도.  
* **불확실성(Uncertainty):** 에이전트가 판단을 유보하는 정도(Vacuity). 토론 과정에서 이 불확실성을 줄여나가는 것이 목표이다.

## ---

**4\. 시스템 아키텍처: 하이브리드 포렌식 모델 (System Architecture)**

제안하는 시스템은 독립적인 분석 능력을 갖춘 4개의 전문 에이전트(Branch)와 이들의 상호작용을 관장하는 중앙 퓨전 엔진(Fusion Engine)으로 구성된다. 이 구조는 제공된 PROJECT\_STRUCTURE.md 문서를 기반으로 확장 설계되었다.1

### **4.1 전문 분석 에이전트 (Specialized Analytic Agents)**

각 에이전트는 입력 이미지 $I \\in \\mathbb{R}^{B \\times 3 \\times H \\times W}$를 받아 특징 벡터 $F \\in \\mathbb{R}^{B \\times K}$와 판정 결과, 그리고 신뢰도 점수를 출력한다.

#### **4.1.1 주파수 분석 에이전트 (Frequency Agent)**

* **역할:** 인간의 시각으로는 인지하기 힘든 생성 모델의 스펙트럼 아티팩트를 탐지한다.  
* **구현 원리:**  
  * **FFT 변환:** 이미지를 주파수 도메인으로 변환하여 고주파수 대역의 이상 징후를 분석한다. GAN이나 CNN 기반 업샘플링(Upsampling) 과정은 종종 스펙트럼 상에 격자무늬(Grid Artifacts)나 특정 주파수 대역의 에너지 집중 현상을 남긴다.1  
  * **방사형 에너지(Radial Energy):** 방위각(Azimuthal) 통합을 통해 1차원 스펙트럼 프로파일을 생성, 자연 이미지의 ![][image1] 붕괴 법칙(Power Spectrum Decay) 위반 여부를 검사한다.  
* **토론 전략:** 시각적으로 완벽한 이미지에 대해 "스펙트럼 불일치"를 근거로 위조 가능성을 제기하는 '내부 고발자' 역할을 수행한다.

#### **4.1.2 노이즈 분석 에이전트 (Noise Agent)**

* **역할:** 카메라 센서 고유의 노이즈 패턴(PRNU)과 생성 모델의 노이즈 잔차(Residual)를 비교 분석한다.  
* **구현 원리:**  
  * **SRM (Spatial Rich Model):** 이미지의 내용(Semantic Content)을 제거하고 순수한 노이즈 성분만을 추출하는 필터 뱅크를 사용한다.1  
  * **MHA (Multi-Head Attention):** 추출된 노이즈 맵에서 장거리 의존성(Long-range dependency)을 분석하여, 인위적으로 주입된 노이즈나 지나치게 매끄러운 영역을 탐지한다.1  
* **토론 전략:** "센서 지문(Fingerprint) 부재"를 강력한 논거로 제시하며, 특히 인페인팅(Inpainting)된 영역을 지적하는 데 특화된다.

#### **4.1.3 공간 분석 에이전트 (Spatial Agent)**

* **역할:** 의미론적(Semantic) 오류와 시각적 부자연스러움을 탐지한다.  
* **구현 원리:**  
  * **Backbone:** Swin Transformer 또는 CLIP Encoder와 같은 대규모 사전 학습 모델을 활용한다.1 이는 텍스트-이미지 불일치나 물리적 비정합성(예: 비대칭적인 눈, 기형적인 손가락)을 포착하는 데 유리하다.  
  * **특징 추출:** 이미지의 전역적 문맥(Global Context)과 국소적 특징(Local Features)을 동시에 고려한다.  
* **토론 전략:** 가장 직관적인 판정을 내리지만, 최신 생성 모델에 의해 가장 쉽게 기만당할 수 있는(Vulnerable) 에이전트이기도 하다. 따라서 다른 에이전트의 검증 대상이 된다.

#### **4.1.4 워터마크 분석 에이전트 (Watermark Agent)**

* **역할:** 디지털 서명 및 비가시 워터마크를 검출하여 '증명된 진본성(Provenance)'을 확인한다.  
* **구현 원리:**  
  * **HiNet:** 스테가노그래피(Steganography) 분석에 특화된 인코더-디코더 네트워크를 사용하여 이미지 내에 은닉된 100-bit 서명을 추출한다.1  
  * **Tamper Mask:** 위조된 영역을 픽셀 단위로 시각화하는 마스크(![][image2])를 생성한다.  
* **토론 전략:** **'Root-of-Trust(신뢰의 뿌리)'** 역할을 수행한다. 이 에이전트가 유효한 워터마크를 검출하면, 다른 에이전트들의 확률적 의심을 무효화(Veto)할 수 있는 강력한 권한을 갖는다.

### **4.2 퓨전 엔진: 토론의 장 (COBRA Fusion Engine)**

4개의 에이전트에서 출력된 결과는 중앙의 **COBRA 퓨전 엔진**으로 수집된다. 이 엔진은 단순한 집계자가 아니라, 에이전트 간의 신뢰도를 평가하고 충돌을 해결하는 **중재자(Moderator)** 역할을 한다. 퓨전 엔진은 에이전트들의 특징 벡터를 결합하고, Dempster-Shafer 이론을 적용하여 최종 판정의 불확실성을 계산한다.1

## ---

**5\. 에이전트 간 토론 메커니즘 상세 설계 (Design of Agent Debate)**

본 장에서는 하이브리드 포렌식 모델 내에서 실제로 토론이 어떻게 발생하고 결론에 도달하는지, 그 구체적인 프로토콜과 알고리즘을 설계한다.

### **5.1 토론 프로토콜의 단계 (Debate Protocol Phases)**

MAD-Sherlock 2과 Debate-to-Detect (D2D) 8 프레임워크를 참조하여, 포렌식에 최적화된 4단계 토론 프로토콜을 제안한다.

| 단계 | 명칭 | 기능 및 활동 | 주요 알고리즘/도구 |
| :---- | :---- | :---- | :---- |
| **Phase 1** | **개별 분석 (Opening)** | 각 에이전트가 독립적으로 이미지를 분석하고 초기 판정(Initial Verdict)과 신뢰도(Confidence)를 제출한다. | FFT, SRM, ViT, HiNet |
| **Phase 2** | **충돌 감지 (Conflict Detection)** | 퓨전 엔진이 에이전트 간의 의견 불일치를 감지한다. 충돌도(![][image3])가 임계값을 초과하면 토론 모드로 진입한다. | Dempster’s Conflict Metric, Variance Check |
| **Phase 3** | **반박 및 재검토 (Rebuttal & Refinement)** | 에이전트들이 타 에이전트의 분석 결과를 참조하여 자신의 분석을 재검토하거나, 상대방의 오류 가능성(예: 공격 당함)을 지적한다. | LLM Wrapper, COBRA Strategies (DRWA, AVGA) |
| **Phase 4** | **최종 판결 (Adjudication)** | 판사 에이전트(Judge)가 모든 주장을 종합하고, 각 에이전트의 신뢰 가중치를 적용하여 최종 결론을 내린다. | Root-of-Trust, Weighted Voting, EDL |

### **5.2 COBRA 합의 전략의 수식적 적용**

COBRA 프레임워크의 3가지 핵심 전략은 토론의 '규칙'을 수학적으로 정의한다.1

#### **5.2.1 Root-of-Trust (RoT): 권위 기반 가중치**

특정 에이전트(예: 워터마크 에이전트)가 명확한 증거(워터마크 검출)를 제시할 경우, 이를 '신뢰 코호트(Trusted Cohort)'로 지정하고 다른 에이전트의 의견을 압도하는 가중치를 부여한다.

![][image4]  
여기서 ![][image5]는 신뢰 그룹(워터마크 에이전트 등), ![][image6]는 비신뢰 그룹, ![][image7]는 신뢰 가중치(![][image8])이다. 이는 토론에서 "결정적 증거(Smoking Gun)"가 제시되었을 때 논쟁을 종결시키는 메커니즘이다.

#### **5.2.2 Dynamic Reliability Weighted Aggregation (DRWA): 동적 신뢰도 조정**

에이전트의 일관성(Consistency)을 기반으로 발언권을 동적으로 조정한다. 만약 주파수 에이전트가 유사한 배치(Batch) 내에서 판정이 심하게 흔들린다면(높은 분산), 해당 에이전트의 신뢰도 가중치를 낮춘다.

![][image9]  
여기서 ![][image10]는 에이전트 출력의 분산이다. 이는 토론에서 "말을 번복하거나 확신이 없는" 참가자의 발언을 배제하는 효과를 낸다.

#### **5.2.3 Adaptive Variance-Guided Attention (AVGA): 반직관적 정보 활용**

대다수의 에이전트가 기만당한 상황(High Variance in Trusted Group)을 대비한 전략이다. 만약 신뢰받던 공간 분석 에이전트가 혼란스러워하는 반면, 통상적으로 무시되던 노이즈 에이전트가 매우 일관된 신호를 보낸다면, AVGA는 주의(Attention)를 노이즈 에이전트로 이동시킨다. 이는 "다수결의 횡포"를 막고 소수의견이 진실일 가능성을 열어두는 안전장치이다.

### **5.3 언어 모델(LLM)을 활용한 의미론적 토론 (Semantic Debate)**

수치적 합의를 넘어, 에이전트들이 자연어(Natural Language)로 소통하는 고차원 토론 레이어를 구현한다. 이는 시스템의 설명 가능성을 극대화한다.4

* **시스템 프롬프트 예시:**  
  * **공간 에이전트:** "시각적으로 얼굴의 대칭이 완벽하고 텍스처가 자연스러워 진본(Real)으로 판단됨 (신뢰도 0.85)."  
  * **주파수 에이전트 (반박):** "동의하지 않음. 시각적으로는 완벽할지 모르나, 고주파수 대역에서 생성 모델 특유의 격자 아티팩트가 발견됨. 이는 업샘플링 과정의 흔적으로 보임 (신뢰도 0.92)."  
  * **판사 에이전트 (결론):** "시각적 분석은 최신 확산 모델에 의해 기만될 가능성이 높음. 반면 주파수 분석이 제시한 물리적 증거가 구체적이므로, 주파수 에이전트의 판단을 채택하여 '위조(Fake)'로 최종 판정함."

이러한 의미론적 토론은 **LangGraph**와 같은 프레임워크를 통해 상태 기반 그래프(State-based Graph)로 구현된다.

## ---

**6\. 구현 방안 (Implementation Strategy)**

본 장에서는 제안된 설계를 실제 소프트웨어로 구현하기 위한 구체적인 기술 스택과 코드 구조를 다룬다.

### **6.1 기술 스택 및 도구**

* **Core Framework:** Python 3.9+, PyTorch 2.0+ (텐서 연산 및 딥러닝 모델링)  
* **Agent Orchestration:** **LangGraph** 4 또는 **Microsoft AutoGen**.5 본 보고서는 복잡한 상태 관리와 순환(Cycle) 구조 지원이 우수한 LangGraph를 권장한다.  
* **LLM Backend:** GPT-4o (복잡한 추론 및 판결), LLaMA-3 (경량화된 에이전트 래퍼).  
* **Logging & Viz:** WandB (학습 로그), Rich (터미널 시각화).

### **6.2 데이터 구조 및 상태 관리 (State Management)**

LangGraph를 사용한 토론 상태(DebateState) 정의는 다음과 같다.

Python

from typing import TypedDict, List, Annotated  
import operator

class AgentOutput(TypedDict):  
    agent\_name: str  
    verdict: str  \# "Real", "Fake"  
    confidence: float  
    evidence\_embedding: List\[float\]  
    reasoning: str  \# Natural language explanation

class DebateState(TypedDict):  
    image\_path: str  
    messages: Annotated\[List\[str\], operator.add\]  \# 토론 로그  
    branch\_outputs: dict\[str, AgentOutput\]        \# 각 브랜치의 분석 결과  
    current\_round: int  
    conflict\_degree: float  
    final\_decision: str

### **6.3 랭그래프(LangGraph) 기반 토론 워크플로우 구현**

토론의 흐름을 제어하는 그래프 구조는 다음과 같이 구현된다. conditional\_edges를 활용하여 충돌 여부에 따라 토론을 지속할지 판결을 내릴지 결정한다.10

Python

from langgraph.graph import StateGraph, END

\# 1\. 노드 정의 (Nodes)  
def analysis\_node(state):  
    \# 4개의 포렌식 브랜치 병렬 실행  
    results \= run\_forensic\_branches(state\['image\_path'\])  
    return {"branch\_outputs": results}

def conflict\_check\_node(state):  
    \# Dempster-Shafer Conflict K 계산  
    k\_val \= calculate\_conflict(state\['branch\_outputs'\])  
    return {"conflict\_degree": k\_val}

def rebuttal\_node(state):  
    \# LLM을 이용한 반박 생성 (COBRA 전략 적용)  
    rebuttals \= generate\_rebuttals(state\['branch\_outputs'\], strategy='AVGA')  
    return {"messages": rebuttals, "current\_round": state\['current\_round'\] \+ 1}

def judge\_node(state):  
    \# 최종 판결  
    verdict \= synthesize\_verdict(state\['messages'\], state\['branch\_outputs'\])  
    return {"final\_decision": verdict}

\# 2\. 그래프 구축 (Graph Construction)  
workflow \= StateGraph(DebateState)

workflow.add\_node("detectives", analysis\_node)  
workflow.add\_node("conflict\_analyzer", conflict\_check\_node)  
workflow.add\_node("debater", rebuttal\_node)  
workflow.add\_node("judge", judge\_node)

workflow.set\_entry\_point("detectives")  
workflow.add\_edge("detectives", "conflict\_analyzer")

\# 3\. 조건부 엣지 (Conditional Logic)  
def decide\_next\_step(state):  
    if state\['branch\_outputs'\]\['watermark'\]\['detected'\]:  
        return "judge"  \# RoT: 워터마크 발견 시 즉시 판결  
    if state\['conflict\_degree'\] \> 0.6 and state\['current\_round'\] \< 3:  
        return "debater" \# 충돌 시 토론 진행  
    return "judge"       \# 합의 도달 시 판결

workflow.add\_conditional\_edges(  
    "conflict\_analyzer",  
    decide\_next\_step,  
    {"debater": "debater", "judge": "judge"}  
)  
workflow.add\_edge("debater", "conflict\_analyzer") \# 토론 후 다시 충돌 확인 (Loop)  
workflow.add\_edge("judge", END)

app \= workflow.compile()

### **6.4 손실 함수 설계 (Loss Functions)**

에이전트들이 '잘 토론하도록' 학습시키기 위해 특별한 손실 함수가 필요하다.

1. **EDL Loss (Evidence Deep Learning):** 각 에이전트가 자신의 불확실성(Uncertainty)을 정확히 출력하도록 학습한다. 분류 정확도뿐만 아니라, 모르는 것을 모른다고 할 때 페널티를 줄인다.1 $$L\_{EDL} \= \\sum (y \- \\hat{p})^2 \+ \\lambda \\cdot KL(Dirichlet |

| Uniform)$$

2\. **Conflictive Loss:** 에이전트 간의 불필요한 충돌을 줄이고(Consensus), 진정한 위조 증거에 대해서만 강하게 주장하도록 유도한다.

![][image11]  
여기서 ![][image3]는 뎀스터-쉐퍼 이론의 충돌 계수이다.

## ---

**7\. 사례 연구 및 시뮬레이션 (Case Studies)**

제안된 시스템의 유효성을 검증하기 위해 가상의 시나리오를 분석한다.

### **7.1 시나리오 A: 고품질 확산 모델 (High-Quality Diffusion Model)**

* **상황:** Stable Diffusion XL로 생성된 인물 사진. 시각적 결함이 거의 없음.  
* **개별 분석:**  
  * Spatial Agent: "Real" (Confidence 0.9) \- 시각적 완벽함에 속음.  
  * Frequency Agent: "Fake" (Confidence 0.7) \- 미세한 스펙트럼 이상 감지.  
  * Noise Agent: "Fake" (Confidence 0.85) \- 센서 노이즈 패턴 부재 확인.  
* **토론 과정:**  
  * **충돌 감지:** Spatial과 Noise 간의 강한 불일치(![][image12]).  
  * **반박:** Noise Agent가 "이미지가 지나치게 깨끗하다(Too pristine)"는 점을 지적하며 Spatial Agent의 판정에 의문을 제기.  
  * **COBRA 적용:** DRWA 전략에 따라, 과거 유사 사례에서 Spatial Agent의 높은 변동성을 감안하여 가중치를 낮춤.  
* **최종 판결:** "Fake". 판사는 Noise Agent의 물리적 증거를 채택.

### **7.2 시나리오 B: 적대적 공격 (Adversarial Attack)**

* **상황:** 진짜 이미지에 비가시 노이즈를 추가하여 분류기를 교란시키는 공격(FGSM 등).  
* **개별 분석:**  
  * Frequency/Spatial Agent: "Fake" (Confidence 0.95) \- 적대적 노이즈에 의해 오분류.  
  * Watermark Agent: "Real" (Confidence 1.0) \- C2PA 서명 검증 성공.  
* **토론 과정:**  
  * **RoT 발동:** Watermark Agent가 신뢰 코호트(![][image5])로 지정됨.  
  * **거부권 행사:** 다른 에이전트들의 "Fake" 판정을 무시.  
* **최종 판결:** "Real". 시스템은 이를 '공격받은 진본(Attacked Real)'으로 분류하고 공격 경고(Attack Warning)를 함께 출력.1

## ---

**8\. 연구 발전 방향 (Research Directions)**

현재의 설계는 강력하지만, 여전히 발전의 여지가 많다. 향후 연구는 다음의 방향으로 진행되어야 한다.

### **8.1 재귀적 토론 (Recursive Debate)**

복잡한 이미지는 한 번의 토론으로 결론이 나지 않을 수 있다. '재귀적 토론'은 큰 문제를 작은 하위 문제로 분할하여 토론하는 방식이다.12 예를 들어, 얼굴 영역에 대해서만 별도의 '소(小) 토론'을 생성하여, 눈동자의 반사광 일치 여부만을 집중적으로 논쟁하는 하위 에이전트 팀을 호출하는 방식이다.

### **8.2 게임 이론 기반 최적화 (Game-Theoretic Optimization)**

토론 과정을 내쉬 균형(Nash Equilibrium)을 찾는 게임으로 모델링한다.13 에이전트들에게 "자신의 판정이 최종 채택될 때" 보상을 주는 경쟁적 환경을 조성하되, 협력적 목표(전체 정확도)를 공유하게 함으로써, 에이전트들이 더 정교한 논리와 증거를 찾도록 유도한다.

### **8.3 적대적 토론 강화 (Adversarial Hardening)**

공격자가 '토론 자체'를 공격할 가능성에 대비해야 한다. 예를 들어, 토론의 혼란을 가중시켜 시간 초과(Time-out)를 유도하거나 판결 불능 상태(Deadlock)를 만드는 공격이다. 이에 대응하기 위해, 토론 과정에 '악마의 변호인(Devil's Advocate)' 에이전트를 일부러 투입하여 시스템의 논리적 허점을 미리 파악하고 강화하는 훈련이 필요하다.15

## ---

**9\. 결론 (Conclusion)**

본 보고서는 멀티 에이전트 이미지 포렌식 시스템의 핵심인 '에이전트 간 토론' 메커니즘을 COBRA 프레임워크와 최신 LLM 토론 프로토콜을 융합하여 설계하였다. 제안된 시스템은 단순한 분류기를 넘어, **주파수, 노이즈, 공간, 워터마크**라는 4가지 관점의 증거를 수집하고, **RoT, DRWA, AVGA** 전략을 통해 논리적으로 충돌을 해결한다.

LangGraph를 활용한 구현 방안과 뎀스터-쉐퍼 이론 기반의 불확실성 관리는 이 시스템이 단순한 이론적 모델을 넘어 실제 환경에서 작동 가능한(Actionable) 솔루션임을 보여준다. 생성형 AI와의 끝없는 창과 방패의 대결에서, '설명 가능한 토론'을 수행하는 이 포렌식 시스템은 디지털 진실을 수호하는 강력한 방패가 될 것이다.

### ---

**참고 문헌 데이터 (Integrated Citations)**

본 보고서는 다음의 문헌 및 자료를 기반으로 작성되었다:

* **COBRA Framework & Aggregation:** 1  
* **System Architecture & Branches:** 1  
* **Multi-Agent Debate (MAD) Protocols:** 2  
* **Agent-based Image Forensics (AIFo):** 21  
* **LangGraph & AutoGen Implementation:** 4  
* **Game Theory & Logic:** 13  
* **Forensic Techniques (FFT, PRNU):** 33

#### **참고 자료**

1. PROJECT\_STRUCTURE.md  
2. MAD-Sherlock: Multi-Agent Debates for Out-of-Context Misinformation Detection, 1월 23, 2026에 액세스, [https://openreview.net/forum?id=Br42izY8eU](https://openreview.net/forum?id=Br42izY8eU)  
3. From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection \- ResearchGate, 1월 23, 2026에 액세스, [https://www.researchgate.net/publication/397231237\_From\_Evidence\_to\_Verdict\_An\_Agent-Based\_Forensic\_Framework\_for\_AI-Generated\_Image\_Detection](https://www.researchgate.net/publication/397231237_From_Evidence_to_Verdict_An_Agent-Based_Forensic_Framework_for_AI-Generated_Image_Detection)  
4. Patterns for Democratic Multi‑Agent AI: Debate-Based Consensus — Part 2, Implementation, 1월 23, 2026에 액세스, [https://medium.com/@edoardo.schepis/patterns-for-democratic-multi-agent-ai-debate-based-consensus-part-2-implementation-2348bf28f6a6](https://medium.com/@edoardo.schepis/patterns-for-democratic-multi-agent-ai-debate-based-consensus-part-2-implementation-2348bf28f6a6)  
5. Multi-Agent Debate — AutoGen \- Microsoft Open Source, 1월 23, 2026에 액세스, [https://microsoft.github.io/autogen/stable//user-guide/core-user-guide/design-patterns/multi-agent-debate.html](https://microsoft.github.io/autogen/stable//user-guide/core-user-guide/design-patterns/multi-agent-debate.html)  
6. A Multi-Agent Debate Framework for Fact Verification with Diverse Tool Augmentation and Adaptive Retrieval \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2601.04742v1](https://arxiv.org/html/2601.04742v1)  
7. MAD: The first work to explore Multi-Agent Debate with Large Language Models :D \- GitHub, 1월 23, 2026에 액세스, [https://github.com/Skytliang/Multi-Agents-Debate](https://github.com/Skytliang/Multi-Agents-Debate)  
8. Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models \- ResearchGate, 1월 23, 2026에 액세스, [https://www.researchgate.net/publication/392106056\_Debate-to-Detect\_Reformulating\_Misinformation\_Detection\_as\_a\_Real-World\_Debate\_with\_Large\_Language\_Models](https://www.researchgate.net/publication/392106056_Debate-to-Detect_Reformulating_Misinformation_Detection_as_a_Real-World_Debate_with_Large_Language_Models)  
9. Reformulating Misinformation Detection as a Real-World Debate with Large Language Models \- ACL Anthology, 1월 23, 2026에 액세스, [https://aclanthology.org/2025.emnlp-main.764.pdf](https://aclanthology.org/2025.emnlp-main.764.pdf)  
10. Multi-agent network \- GitHub Pages, 1월 23, 2026에 액세스, [https://langchain-ai.github.io/langgraph/tutorials/multi\_agent/multi-agent-collaboration/](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/)  
11. Group Chat — AutoGen \- Microsoft Open Source, 1월 23, 2026에 액세스, [https://microsoft.github.io/autogen/stable//user-guide/core-user-guide/design-patterns/group-chat.html](https://microsoft.github.io/autogen/stable//user-guide/core-user-guide/design-patterns/group-chat.html)  
12. Recursive Debate Protocol \- Emergent Mind, 1월 23, 2026에 액세스, [https://www.emergentmind.com/topics/recursive-debate-protocol](https://www.emergentmind.com/topics/recursive-debate-protocol)  
13. 1월 23, 2026에 액세스, [https://web.xidian.edu.cn/yszheng/files/20190318\_213757.pdf](https://web.xidian.edu.cn/yszheng/files/20190318_213757.pdf)  
14. GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2510.08872v1](https://arxiv.org/html/2510.08872v1)  
15. How to Break the Confirmation Bias Loop and Get AI to Play Devil's Advocate | JD Meier, 1월 23, 2026에 액세스, [https://jdmeier.com/how-to-break-confirmation-bias-loop/](https://jdmeier.com/how-to-break-confirmation-bias-loop/)  
16. MAD-Sherlock: Multi-Agent Debate for Visual Misinformation Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2410.20140v3](https://arxiv.org/html/2410.20140v3)  
17. MAD-Sherlock: Multi-Agent Debates for Out-of-Context Misinformation Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2410.20140v1](https://arxiv.org/html/2410.20140v1)  
18. \[2410.20140\] MAD-Sherlock: Multi-Agent Debate for Visual Misinformation Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/abs/2410.20140](https://arxiv.org/abs/2410.20140)  
19. MAD-Sherlock: Multi-Agent Debates for Out-of-Context Misinformation Detection \- ChatPaper, 1월 23, 2026에 액세스, [https://chatpaper.com/paper/71502](https://chatpaper.com/paper/71502)  
20. MAD-Sherlock: Multi-Agent Debate for Visual Misinformation Detection \- Adobe Research, 1월 23, 2026에 액세스, [https://research.adobe.com/publication/mad-sherlock-multi-agent-debate-for-visual-misinformation-detection/](https://research.adobe.com/publication/mad-sherlock-multi-agent-debate-for-visual-misinformation-detection/)  
21. \[2511.00181\] From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/abs/2511.00181](https://arxiv.org/abs/2511.00181)  
22. From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2511.00181v1](https://arxiv.org/html/2511.00181v1)  
23. From Evidence to Verdict: An Agent-Based Forensic Framework for, 1월 23, 2026에 액세스, [https://chatpaper.com/paper/206278](https://chatpaper.com/paper/206278)  
24. Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2509.05396v1](https://arxiv.org/html/2509.05396v1)  
25. LangGraph Multi-Agent Systems Tutorial 2026, 1월 23, 2026에 액세스, [https://langchain-tutorials.github.io/langgraph-multi-agent-systems-2026/](https://langchain-tutorials.github.io/langgraph-multi-agent-systems-2026/)  
26. iason-solomos/Deb8flow: A Langgraph-based repository which runs a debate between debater agents \- GitHub, 1월 23, 2026에 액세스, [https://github.com/iason-solomos/Deb8flow](https://github.com/iason-solomos/Deb8flow)  
27. Building a Multi-Agent Debate System with LangGraph \- Engineering Notes \- Muthukrishnan, 1월 23, 2026에 액세스, [https://notes.muthu.co/2025/10/building-a-multi-agent-debate-system-with-langgraph/](https://notes.muthu.co/2025/10/building-a-multi-agent-debate-system-with-langgraph/)  
28. Multi-Agent Debate for LLM Judges with Adaptive Stability Detection \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2510.12697v1](https://arxiv.org/html/2510.12697v1)  
29. LangGraph Tutorial: Implementing Multi-Response Agent Architecture \- Unit 1.3 Exercise 3, 1월 23, 2026에 액세스, [https://aiproduct.engineer/tutorials/langgraph-tutorial-implementing-multi-response-agent-architecture-unit-13-exercise-3](https://aiproduct.engineer/tutorials/langgraph-tutorial-implementing-multi-response-agent-architecture-unit-13-exercise-3)  
30. Achieving Unanimous Consensus in Decision Making Using Multi-Agents \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2504.02128v1](https://arxiv.org/html/2504.02128v1)  
31. Game-Theoretic LLM: Agent Workflow for Negotiation Games | Department of Biostatistics, 1월 23, 2026에 액세스, [https://www.vumc.org/biostatistics/game-theoretic-llm-agent-workflow-negotiation-games](https://www.vumc.org/biostatistics/game-theoretic-llm-agent-workflow-negotiation-games)  
32. From Self-Check to Consensus: Bayesian Strategic Decoding in Large Language Models \- OpenReview, 1월 23, 2026에 액세스, [https://openreview.net/pdf/1b41e05b218d478917e719a479330a4b6c7bee60.pdf](https://openreview.net/pdf/1b41e05b218d478917e719a479330a4b6c7bee60.pdf)  
33. Decoding large language models for radiology: strategies for fine-tuning and prompt engineering \- PMC \- NIH, 1월 23, 2026에 액세스, [https://pmc.ncbi.nlm.nih.gov/articles/PMC12429228/](https://pmc.ncbi.nlm.nih.gov/articles/PMC12429228/)  
34. Methods and Trends in Detecting AI-Generated Images: A Comprehensive Review \- arXiv, 1월 23, 2026에 액세스, [https://arxiv.org/html/2502.15176v2](https://arxiv.org/html/2502.15176v2)  
35. MMCTAgent: Enabling multimodal reasoning over large video and image collections, 1월 23, 2026에 액세스, [https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/](https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/)  
36. CHELSEA234/M2F2\_Det: Deepfake \+ LLM (CVPR25 Oral) \- GitHub, 1월 23, 2026에 액세스, [https://github.com/CHELSEA234/M2F2\_Det](https://github.com/CHELSEA234/M2F2_Det)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB8AAAAYCAYAAAACqyaBAAAA/klEQVR4Xu2VURECMQxE4wAFOMABDnCABBzgAClIwAIW0ICIo9teoBfadMt0+Lo3k59c2L0muSKysvIbB5v4F9sQJ5sscAxxk1Rf5TwHy8MmClwk1cF8Ms/eSY0e8y+xAqjByVW/So85BFvzRptdw5wec0YUWkxdpMfcm/dO0iI+5aO5X1QUYM2xRN7mwkhPjZccas62ktWLMMWbEFebrAA9r0MLGHPWGDNnOxRhzFnB4qXi0TLHFnvPc6CFbafALPEDbHIN7/OytA4SsddrHpZSrgZq6WVrwVynit7lw2DEUIPR3OcYRmve+ieC7jAvSoNvlpkfFgw7NBR21jQvU4ZMmf1QOckAAAAASUVORK5CYII=>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGEAAAAYCAYAAADqK5OqAAACSElEQVR4Xu2YgVHDMAxFswETsAEbsAEbMAIbsAEjMAIjsAIrMANDQN+1//j3sR0nbSmlfne+NEoUy5IsJZ2mwWAwGJyI28143IzP3fF6M25Cxnkv3PsyfevCw+78w2TMy/nrtJ3z4pHDnfuCrBccnLo4+y1kBGGwA2c8h+x92ma0Q8ZehQyeUjD9DALPcxmB6oJsIIIoazu1INK6F72ScYcGp9xN2zlZGIMFc8SxskdloATX07nISmWIZ/q9eS7c4diTuy0DPIsWktF1yBJtYY6/jWzDcZ5l/EbGyHIgPIAMBbWGHF8LAEif6/jGS1QrIaqwA3I7JdrSrXvmwFgM9IFDetC8cqSjUlPKPjVNp6cf4I9WQ5U+94EHYXGSooyhLQer7MztlhrKPOapZdYcrSBQGqGUgehl2Sz1A6d3J6QdyGq7sYkW0MoOLW7NJOi2FtxLKwiyT1npoJcZXXKgSMfnueAZua7SXF1ocSiXjFOz1vXe8iFKjllDLQhyBPN4o/WmzfBvA40sG/u8HcHci00VV+TBvqVxuIxqlasamSn74EFwR5aceVaoHwgWpPIE/lsLXgL3K3Nro3f7ehAYJIu+fn0NZ4c7GdzRWUaQL+0HxwyCy5ba9afIzFYQ8l18bT84VjmSbZRKzbG6Hp+aNFxfxCnXH1ZryB21llIQANv0waTvhbMBh+c25i2g5GwvU0uhaR7COT6/BwF0jd5wFk06X918cdnk8j7GmhKD09Bd87Em3dIQKpf72Hgx7PO3xWAwGAwG/44v197UDvGwchoAAAAASUVORK5CYII=>

[image3]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAYCAYAAAD3Va0xAAAArElEQVR4XmNgGAVDH7QD8XYg/g/Fr6F8ZHACKgfDFajSqACmCBvIZMA0HCcAGXITXZAB4hovdEFcIJIBYhCIRgYgMX40MbwA5BJkb+kwQMKKZIAcPtOhbGzeJAhgGkGuALkGX8DjBLDwQdYIil4QH+Q6ogF6+MAAuuEEAS4NMAus0SVwAZBiUFpBB6Box2UJBoCFBXr6gQGYQbLoEjCAnLeQMTJAl0OXHwX0BAAg5TzkJNCs6AAAAABJRU5ErkJggg==>

[image4]: <data:image/png;base64,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>

[image5]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAAYCAYAAAD3Va0xAAAAn0lEQVR4XmNgGAVDFywH4v8kYJwAJMmPRQybJmxiYAAyYDq6IANEw010QQY8BoG8hQ4iGSAaQDQ6wKYeDCrQBYDgNQNum2XRBfABXOFDMsAVPiSBTAbc4UMSwBc+JAG6hg9IHhTbONWBJEEGgcIJF0B2LYrLvaACuDAyAOWAE2hiZAGQwSCLKQagMLFG4uswYGZ2ogEoeWyH0iRlF/oCAAo4N+bDJ1hCAAAAAElFTkSuQmCC>

[image6]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAAoklEQVR4Xu2TWw2AMAxF6wAjOMABDnCCAyRhAQtoQATshg3KaPdIxtc4SUPSrq9LSvRTD7OxzdhubbE+x8BiMB5TaegupoF4MiOdCZ0fYGQVdOto9HQ2TSZWMCSFSEzsULMXleq3+k5GqJkIErQp8KNa32nBdUEKfB9MJE+BYjg7Cf5eyr2KctMmgzx4Xww0w+0Xw19RkyULFIXGWL/otN9yAJWgNpuWLd5bAAAAAElFTkSuQmCC>

[image7]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAAuElEQVR4Xu2SWw0CMRBF6wAFOFgHOMABEnCAg5WABCRgAQtoWBHQk3Tgcrc0oV989CSTnTvtdh6ZlAaDwW9cs508mNmLfzb9laV8H9kOEr+XWICvuspFfC5rBWgqD+YSaxJt1i6jdxbTBLA1/YKfaTGgdU9A9ZNoisCqeLu3ElM0IXDerNC1x+LBY3qfY+gVXqE/6LPbpHXCD5hNPBJrFGuD6eygOb8emvPrIdr1teqGLWCuPoo/5wkTqzM9ndHupQAAAABJRU5ErkJggg==>

[image8]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEYAAAAYCAYAAABHqosDAAABjElEQVR4Xu2XgVHDMAxFvQETsAEbsAEbMAIbsAEjMAIjsAIrMEOHgDyaf6f8qLTKJfRo/e50V8uyLcuy4rbW6XQ6nU5nXW4G+XLlCXy2/Tjk0fr+NdqUpAL2d6G9G+Q1tC+CamDe29z+NtH9KfdtelJrUA0MtgTHSa8Uhs+uHHgIv0m12K7AWDlE2vKbIGVU11gzMBM9jqojRkzFSVQdiLy5ou3X1dqR6hpVv2YBGJnMEx1GGU/LJ3gZdVWeXBEga+SQhK9MhU0Co+uTbZq2p7tPSNE6N5sEJiq5OoIr5UZkUyycBBM5FdUWJKtn4pwZM9OjjNfoY9RFYuCA/lMzBtsYVBXjbPzMuSMsCQz7c9ID84mzxRQYaob6kd9qCHAdD2UB48kkDgVZ8tDKfI34ZpW5kYPvGJReeKOhn2LlGe51yiGTmJ9TPGab4b5G1BeDk/nO2tkX8sc5TSKD+F/CH2XV+rIF8s0lBlf7ckgC9HyV2aeXicUwaVYfrh6dwpLUv2i4k9QFv2KdzhXyDXn0m5d31h9RAAAAAElFTkSuQmCC>

[image9]: <data:image/png;base64,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>

[image10]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAZCAYAAADTyxWqAAAAsklEQVR4XmNgGAV4AD8QW6MLkgOWA7EsA8TA/0AciSpNGgAZoANle0H5ZIPtDBBXgQDIhRQZhgxABt9EFyQHgFz3Gl2QXHACXYBcgGzQdCQ2CqhggAQoNgxKEiCALo41AkDRja4IGbdD1aGLYxgGMwg5VYO8gqGQGADShO53kMEkGwbKDtg0gbyFTRwvACU8bJqwhgchgM8wUHYhCWDLXyA+2aUBLPeDMCiLkOyiUTAIAAD3mzld4iNdwwAAAABJRU5ErkJggg==>

[image11]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmAAAAA4CAYAAABaKURjAAAEo0lEQVR4Xu3dgY3jRBQG4O2ACujgOqADOqAEOrgOKIESKIEWaIEaKAL2190Tw9OM7awuTnC+TxrtZuwkY8fSe/tmnH17AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD+6+fecRGfewcAwMoP7+1T77yTv3vHhXz/3v7onQDwCL+/t7/evgTetDxO4/F+evv3czmjepPrIEnKSsZwxji21PVZ5+XPr49H6avtOaYfh22/vrdfhscA8DC/vX0JVlvBl8c5IwFLlW1W/RqTnTPGcVSNZ2YvyVo9DwBOtRXMeLwzEp+8R5KwLWeM44hMx2YsSbS6VLz2pmszDdmrZgBwOgnYczsj8Tny+Z8xjiOSeGUsY8X2u699R+R5R/cFgLuoYLQ1ZcNjrRKf3K1YyfPqzsWsf0q1J9PMSVLyOr16VK+zZzWOs/U/GLJW7tbF9UeOFwDupqoJCc48p1ni05OuWRKV6bgsSC/1Otk320oStHG/ldk4HmFMwJJ49YTyiDxnXJwPAKfq1YRH2Vt/dE91d9/RdvbNCj3xqbv8uvRVJaim5MbzWgvqu/QdWRPVx/EIVbEd/3D4yDX8DMcCwAvbC15nVMZSjUkwrHEkyM6qMlvjHD0ymRtlHEfblp4srBKm8bOsuxqPJmBHkpGj+0U/vq12S0JbiVev4KUvU5FHrc4hANzd3vqvrBs6Q8aQsYzJXio5PaAeCf63LMa+t55obLUtPfFZJQ89weqfbR73pDb6668c3S/68W21WxKwjGH2+a76V1bnEADurqoJqwB4S0D7qATgVVLwEUk4bl0P1KcY99rqfN1LT3zyeLbovL5Qt+T38Ut2Z+c5jiYjfRyPsEq0qv9oxfYZjgWAF7UKZjGrQCWxqTZ+11IFs3qtBMEkQnmN/By3jer9Z+MYH2cceZ1eqevjGV9rnKL6v+vJwux8Re+f7TOTz2mVnI36OM5Wn3G/DiKJfLYdOY7IvnuVRwC4ix6wo6Yle//4BZfZVnfgjfsloGW/Sn7GbamwzAJe9ukVpV4VSwKWO9bGviPjuYqedNQ065gEV3IyqoQk577a7M6/VYI8qvecJT9nqSnWfr2Uum6PVMH2jhcAvrkKVFttrCCtvrgywX0MyAnutV+SpnFaa/b8mPXneb36lv0q8K7G80zrv76FSozGNsr5r/7ZlOS4vbdu1heV9MzaWfr79vev6tfYZuejrK4fAHgqSQRmAS1BrC+cr/VXCf5jxWsV8Gb9e32r8Xxk/ddV5fyvbqLIuexTiembVSivaLxOAeBp9WpWJNnpidL4ePy91m/1qaPZtFlUX1XBkiwkYNbzt8ZT+8ym2l7JLMkqs21j9fLqXuU4AbiAWkOUyso4PZhglv5ebRmDXBKtPK8H/TyerSnq3+CepKpPd87Gk5+18P/V1XRs/xdFNaU4k/Pek+SrSSLfr0MAeBm1bof7qv8FWUnyXoJ15c8kxz6bugaAl1AJwZW+KuJKetXsKlS+AHh5r7LgGwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAPf8ASOSOyMTVy0IAAAAASUVORK5CYII=>

[image12]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEQAAAAYCAYAAABDX1s+AAABiUlEQVR4Xu2WYVEEMQyF6wAFOMABDnCABBycAyQgAQlYwAIaEAH3Zvdx2ZC37XZ7ywyTbyY/Nmm3SZqmLSVJkiRJjuL5LG9n+Zrlc/62vM82ymlpPoyXcvHB+6i4KdN4xAm/vdxehi7hQhFPpd2Ba4FNgZDHov21cJwSCYwfXlkmJx68sgISOBLusge62lqvJfYfFYNkhTCLfgB0cGYrmIOjhxIfAYJSCYn0lsiOYxJt/g8w2ol3ZQpoL0zM3uOmAlf6GtU59sdsXKsZ7AD/g/RUnApc6ddAC5CNlDAB2E1UR89CraBasM6WxCh/lF6hetEC24UJriN8j+oBEazE6m6V3/4RpVdg0+1NFeL7B9m62Fb+IiEYW31DqZ8yUffesJOeI8OHo0f5HoE4muLBoKiMeN5aF6zBptoD+5oHOlzJFlUBrMjVhLBX+PcHYUJayjpi1LUL4IcNFj75JLGSovVoCxNCoxeLt3n7GqMfZgQ+oJrpv98oVnV0HPm483MOofacTpIk+Td8AwxYm4lBjRaVAAAAAElFTkSuQmCC>